{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split, validation_curve\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(592380, 28)\n"
     ]
    }
   ],
   "source": [
    "# Load in training and test set data\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "train = train.dropna()\n",
    "train = train.drop(['id'], axis=1)\n",
    "\n",
    "# train = train.fillna(train.mean())\n",
    "test_ids = test['id']\n",
    "test = test.drop(['id'], axis=1)\n",
    "\n",
    "# Replace NaN values with 0\n",
    "# test = test.fillna(0)\n",
    "test = test.fillna(test.mean())\n",
    "\n",
    "train_data = train.drop(['y'], axis=1)\n",
    "# Normalize training and test data\n",
    "min_max_scaler = preprocessing.MinMaxScaler().fit(train_data)\n",
    "train_data = pd.DataFrame(min_max_scaler.transform(train_data))\n",
    "train_labels = pd.DataFrame(train.loc[:,'y']).to_numpy().ravel()\n",
    "test = pd.DataFrame(min_max_scaler.transform(test))\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(train_data, train_labels, \n",
    "                                                    test_size=0.2, random_state=155155155)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_price</th>\n",
       "      <th>mid</th>\n",
       "      <th>opened_position_qty</th>\n",
       "      <th>closed_position_qty</th>\n",
       "      <th>transacted_qty</th>\n",
       "      <th>d_open_interest</th>\n",
       "      <th>bid1</th>\n",
       "      <th>bid2</th>\n",
       "      <th>bid3</th>\n",
       "      <th>bid4</th>\n",
       "      <th>...</th>\n",
       "      <th>bid2vol</th>\n",
       "      <th>bid3vol</th>\n",
       "      <th>bid4vol</th>\n",
       "      <th>bid5vol</th>\n",
       "      <th>ask1vol</th>\n",
       "      <th>ask2vol</th>\n",
       "      <th>ask3vol</th>\n",
       "      <th>ask4vol</th>\n",
       "      <th>ask5vol</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3842.8</td>\n",
       "      <td>3843.4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>-43</td>\n",
       "      <td>3843.0</td>\n",
       "      <td>3842.8</td>\n",
       "      <td>3842.4</td>\n",
       "      <td>3842.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3844.0</td>\n",
       "      <td>3844.3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>-69</td>\n",
       "      <td>3843.8</td>\n",
       "      <td>3843.6</td>\n",
       "      <td>3843.2</td>\n",
       "      <td>3843.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3843.8</td>\n",
       "      <td>3843.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>-30</td>\n",
       "      <td>3843.0</td>\n",
       "      <td>3842.8</td>\n",
       "      <td>3842.4</td>\n",
       "      <td>3842.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3843.2</td>\n",
       "      <td>3843.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-35</td>\n",
       "      <td>3842.8</td>\n",
       "      <td>3842.4</td>\n",
       "      <td>3842.0</td>\n",
       "      <td>3841.8</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3843.6</td>\n",
       "      <td>3844.2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-5</td>\n",
       "      <td>3843.8</td>\n",
       "      <td>3843.4</td>\n",
       "      <td>3843.2</td>\n",
       "      <td>3843.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   last_price     mid  opened_position_qty   closed_position_qty  \\\n",
       "1      3842.8  3843.4                   6.0                 49.0   \n",
       "2      3844.0  3844.3                   7.0                 77.0   \n",
       "3      3843.8  3843.4                   3.0                 34.0   \n",
       "4      3843.2  3843.1                   3.0                 38.0   \n",
       "5      3843.6  3844.2                  12.0                 17.0   \n",
       "\n",
       "   transacted_qty  d_open_interest    bid1    bid2    bid3    bid4  ...  \\\n",
       "1            55.0              -43  3843.0  3842.8  3842.4  3842.0  ...   \n",
       "2            84.0              -69  3843.8  3843.6  3843.2  3843.0  ...   \n",
       "3            37.0              -30  3843.0  3842.8  3842.4  3842.0  ...   \n",
       "4            41.0              -35  3842.8  3842.4  3842.0  3841.8  ...   \n",
       "5            29.0               -5  3843.8  3843.4  3843.2  3843.0  ...   \n",
       "\n",
       "   bid2vol  bid3vol  bid4vol  bid5vol  ask1vol  ask2vol  ask3vol  ask4vol  \\\n",
       "1        6       11        1        6        1        4        4        1   \n",
       "2        1        4       21       12        1       16       10        4   \n",
       "3       13       12        2        4        2        7        1        2   \n",
       "4       12        2        2        4        1        3        1       11   \n",
       "5        6        1        2       17        1       12       15       10   \n",
       "\n",
       "   ask5vol  y  \n",
       "1       13  0  \n",
       "2        9  0  \n",
       "3       11  1  \n",
       "4       15  1  \n",
       "5        3  0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview training set data\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.497696</td>\n",
       "      <td>4.495558</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.051887</td>\n",
       "      <td>0.043651</td>\n",
       "      <td>0.728507</td>\n",
       "      <td>4.494737</td>\n",
       "      <td>4.494737</td>\n",
       "      <td>4.500659</td>\n",
       "      <td>4.500659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018349</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.014815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022901</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030075</td>\n",
       "      <td>0.007463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.348255</td>\n",
       "      <td>4.346167</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.778281</td>\n",
       "      <td>4.345395</td>\n",
       "      <td>4.345395</td>\n",
       "      <td>4.351120</td>\n",
       "      <td>4.351120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007246</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075630</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.053435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.494404</td>\n",
       "      <td>4.494571</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.782805</td>\n",
       "      <td>4.491447</td>\n",
       "      <td>4.490789</td>\n",
       "      <td>4.496706</td>\n",
       "      <td>4.496706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064220</td>\n",
       "      <td>0.123188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042017</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.022901</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007519</td>\n",
       "      <td>0.029851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.218565</td>\n",
       "      <td>4.217835</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009434</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>4.215132</td>\n",
       "      <td>4.215132</td>\n",
       "      <td>4.220685</td>\n",
       "      <td>4.219368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064220</td>\n",
       "      <td>0.028986</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075758</td>\n",
       "      <td>0.037594</td>\n",
       "      <td>0.007463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.533246</td>\n",
       "      <td>4.531425</td>\n",
       "      <td>0.018058</td>\n",
       "      <td>0.009135</td>\n",
       "      <td>-0.003968</td>\n",
       "      <td>0.773756</td>\n",
       "      <td>4.529605</td>\n",
       "      <td>4.529605</td>\n",
       "      <td>4.535573</td>\n",
       "      <td>4.535573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.015504</td>\n",
       "      <td>0.007634</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015038</td>\n",
       "      <td>0.022388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  4.497696  4.495558  0.012500  0.051887  0.043651  0.728507  4.494737   \n",
       "1  4.348255  4.346167  0.012500  0.000000  0.000000  0.778281  4.345395   \n",
       "2  4.494404  4.494571  0.025000  0.000000  0.003968  0.782805  4.491447   \n",
       "3  4.218565  4.217835  0.000000  0.009434  0.003968  0.769231  4.215132   \n",
       "4  4.533246  4.531425  0.018058  0.009135 -0.003968  0.773756  4.529605   \n",
       "\n",
       "         7         8         9   ...        16        17        18        19  \\\n",
       "0  4.494737  4.500659  4.500659  ...  0.018349  0.108696  0.014815  0.000000   \n",
       "1  4.345395  4.351120  4.351120  ...  0.000000  0.007246  0.007407  0.000000   \n",
       "2  4.490789  4.496706  4.496706  ...  0.064220  0.123188  0.000000  0.000000   \n",
       "3  4.215132  4.220685  4.219368  ...  0.064220  0.028986  0.022222  0.016949   \n",
       "4  4.529605  4.535573  4.535573  ...  0.000000  0.028986  0.000000  0.016949   \n",
       "\n",
       "         20        21        22        23        24        25  \n",
       "0  0.000000  0.000000  0.022901  0.000000  0.030075  0.007463  \n",
       "1  0.075630  0.023256  0.053435  0.000000  0.000000  0.000000  \n",
       "2  0.042017  0.046512  0.022901  0.000000  0.007519  0.029851  \n",
       "3  0.000000  0.000000  0.000000  0.075758  0.037594  0.007463  \n",
       "4  0.016807  0.015504  0.007634  0.000000  0.015038  0.022388  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview test set data\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(419920, 27)\n",
      "(191859, 26)\n",
      "(335936, 26)\n",
      "(83984, 26)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(train_X.shape)\n",
    "print(test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature ask1vol (0.060043)\n",
      "2. feature bid1vol (0.050533)\n",
      "3. feature bid3vol (0.046947)\n",
      "4. feature bid2vol (0.046786)\n",
      "5. feature ask3vol (0.046635)\n",
      "6. feature ask2vol (0.046567)\n",
      "7. feature bid4vol (0.046290)\n",
      "8. feature bid5vol (0.046104)\n",
      "9. feature ask4vol (0.045787)\n",
      "10. feature ask5vol (0.045689)\n",
      "11. feature last_price (0.044939)\n",
      "12. feature d_open_interest (0.039219)\n",
      "13. feature mid (0.034316)\n",
      "14. feature transacted_qty (0.033044)\n",
      "15. feature ask1 (0.032160)\n",
      "16. feature ask5 (0.031706)\n",
      "17. feature bid1 (0.031567)\n",
      "18. feature bid5 (0.031268)\n",
      "19. feature closed_position_qty (0.030791)\n",
      "20. feature ask4 (0.030493)\n",
      "21. feature bid4 (0.030170)\n",
      "22. feature ask2 (0.030164)\n",
      "23. feature ask3 (0.030009)\n",
      "24. feature bid2 (0.029707)\n",
      "25. feature bid3 (0.029617)\n",
      "26. feature opened_position_qty  (0.029450)\n"
     ]
    }
   ],
   "source": [
    "# Feature importances\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "feature = ExtraTreesClassifier(n_estimators=250, random_state=0).fit(train_data, train_labels)\n",
    "importances = feature.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(train_data.shape[1]):\n",
    "    print(\"%d. feature %s (%f)\" % (f + 1, train.columns[indices[f]], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classification error: 0.9421030420052702\n",
      "Validation classification error: 0.9414586293996641\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "lin_reg = LinearRegression().fit(train_X, train_y)\n",
    "print('Training classification error: ' + str(1 - lin_reg.score(train_X, train_y)))\n",
    "print('Validation classification error: ' + str(1 - lin_reg.score(test_X, test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classification error: 0.3683201562202324\n",
      "Validation classification error: 0.36711754619927606\n"
     ]
    }
   ],
   "source": [
    "# Linear SVC \n",
    "svc = LinearSVC().fit(train_X, train_y)\n",
    "print('Training classification error: ' + str(1 - svc.score(train_X, train_y)))\n",
    "print('Validation classification error: ' + str(1 - svc.score(test_X, test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classification error: 0.36938702610020957\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression on original dataset\n",
    "log_reg = LogisticRegression().fit(train.loc[:,'last_price':'ask5vol'], train.loc[:,'y'])\n",
    "print('Training classification error: ' + str(1 - log_reg.score(train.loc[:,'last_price':'ask5vol'], train.loc[:,'y'])))\n",
    "# print('Validation classification error: ' + str(1 - log_reg.score(test_X, test_y)))\n",
    "\n",
    "# Predict probabilities on validation set\n",
    "lr_pred = log_reg.predict_proba(test.to_numpy())\n",
    "# Probabilities of being labeled 1\n",
    "lr_pred = pd.DataFrame(lr_pred[:,1], columns=['Predicted'])\n",
    "lr_pred.insert(0, 'id', test_ids)\n",
    "lr_pred.to_csv(\"lr_probs_whole_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jksun/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classification error: 0.3693501143074871\n",
      "Validation classification error: 0.3708920746808916\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression on train and test split\n",
    "log_reg = LogisticRegression().fit(train_X, train_y)\n",
    "print('Training classification error: ' + str(1 - log_reg.score(train_X, train_y)))\n",
    "print('Validation classification error: ' + str(1 - log_reg.score(test_X, test_y)))\n",
    "\n",
    "# # Predict labels on validation set\n",
    "# lr_pred = log_reg.predict(test.to_numpy())\n",
    "# lr_pred = pd.DataFrame(lr_pred, columns=['Predicted'])\n",
    "# lr_pred.insert(0, 'id', test_ids)\n",
    "# lr_pred.to_csv(\"lr_labels_submission.csv\", index=False)\n",
    "\n",
    "# Predict probabilities on validation set\n",
    "lr_pred = log_reg.predict_proba(test.to_numpy())\n",
    "# Probabilities of being labeled 1\n",
    "lr_pred = pd.DataFrame(lr_pred[:,1], columns=['Predicted'])\n",
    "lr_pred.insert(0, 'id', test_ids)\n",
    "lr_pred.to_csv(\"lr_probs_split_submission3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classification error: 0.37113021527910073\n",
      "Test classification error: 0.37203514955229566\n"
     ]
    }
   ],
   "source": [
    "# SGD Classifier - high errors\n",
    "sgd_reg = SGDClassifier(early_stopping=True)\n",
    "sgd_reg.fit(train_X, train_y)\n",
    "print('Training classification error: ' + str(1 - sgd_reg.score(train_X, train_y)))\n",
    "print('Test classification error: ' + str(1 - sgd_reg.score(test_X, test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classification error: 0.3572168508287292\n",
      "Validation classification error: 0.3605210516288817\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Classifier - best so far\n",
    "grad_boost = GradientBoostingClassifier().fit(train_X, train_y)\n",
    "print('Training classification error: ' + str(1 - grad_boost.score(train_X, train_y)))\n",
    "print('Validation classification error: ' + str(1 - grad_boost.score(test_X, test_y)))\n",
    "\n",
    "# Predict probabilities on validation set\n",
    "grad_pred = grad_boost.predict_proba(test.to_numpy())\n",
    "# Probabilities of being labeled 1\n",
    "grad_pred = pd.DataFrame(grad_pred[:,1], columns=['Predicted'])\n",
    "grad_pred.insert(0, 'id', test_ids)\n",
    "grad_pred.to_csv(\"grad_probs_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = [5, 8, 15, 25, 30]\n",
    "min_samples_split = [2, 5, 10, 15, 100]\n",
    "min_samples_leaf = [1, 2, 5, 10] \n",
    "\n",
    "hyperF = dict(max_depth = max_depth,  \n",
    "              min_samples_split = min_samples_split, \n",
    "             min_samples_leaf = min_samples_leaf)\n",
    "\n",
    "gridF = GridSearchCV(GradientBoostingClassifier(), hyperF)\n",
    "bestF = gridF.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classification error: 0.3593988140598209\n",
      "Validation classification error: 0.361175938273957\n"
     ]
    }
   ],
   "source": [
    "# Adaboost Classifier - predicted probabilities are similar\n",
    "ada_boost = AdaBoostClassifier(n_estimators=100).fit(train_X, train_y)\n",
    "print('Training classification error: ' + str(1 - ada_boost.score(train_X, train_y)))\n",
    "print('Validation classification error: ' + str(1 - ada_boost.score(test_X, test_y)))\n",
    "\n",
    "# Predict probabilities on validation set\n",
    "ada_pred = ada_boost.predict_proba(test.to_numpy())\n",
    "# Probabilities of being labeled 1\n",
    "ada_pred = pd.DataFrame(ada_pred[:,1], columns=['Predicted'])\n",
    "ada_pred.insert(0, 'id', test_ids)\n",
    "ada_pred.to_csv(\"ada_probs_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classification error: 0.38692489045532485\n",
      "Validation classification error: 0.4119117927224233\n"
     ]
    }
   ],
   "source": [
    "# Gaussian NB Classifier\n",
    "gauss_boost = GaussianNB().fit(train_X, train_y)\n",
    "print('Training classification error: ' + str(1 - gauss_boost.score(train_X, train_y)))\n",
    "print('Validation classification error: ' + str(1 - gauss_boost.score(test_X, test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classification error: 0.42812619070299107\n",
      "Validation classification error: 0.43185606782244235\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier\n",
    "min_samples_leaf = np.arange(1, 26)\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=5, min_samples_leaf=16, \n",
    "                              min_samples_split=2, class_weight={0: 0.5, 1: 1}, \n",
    "                              random_state=0).fit(train_X, train_y)\n",
    "print('Training classification error: ' + str(1 - tree.score(train_X, train_y)))\n",
    "print('Validation classification error: ' + str(1 - tree.score(test_X, test_y)))\n",
    "# Predict probabilities on validation set\n",
    "tree_pred = tree.predict_proba(test.to_numpy())\n",
    "# Probabilities of being labeled 1\n",
    "tree_pred = pd.DataFrame(tree_pred[:,1], columns=['Predicted'])\n",
    "tree_pred.insert(0, 'id', test_ids)\n",
    "tree_pred.to_csv(\"tree_probs_submission_weights.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classification error: 0.00038400171461228094\n",
      "Validation classification error: 0.3703681653648314\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "forest = RandomForestClassifier(random_state=0).fit(train_X, train_y)\n",
    "print('Training classification error: ' + str(1 - forest.score(train_X, train_y)))\n",
    "print('Validation classification error: ' + str(1 - forest.score(test_X, test_y)))\n",
    "\n",
    "# Predict probabilities on validation set\n",
    "forest_pred = forest.predict_proba(test.to_numpy())\n",
    "# Probabilities of being labeled 1\n",
    "forest_pred = pd.DataFrame(forest_pred[:,1], columns=['Predicted'])\n",
    "forest_pred.insert(0, 'id', test_ids)\n",
    "forest_pred.to_csv(\"forest_probs_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classification error: 0.3630691560297199\n",
      "Validation classification error: 0.3623904553248237\n"
     ]
    }
   ],
   "source": [
    "# Voting Classifier 1\n",
    "estimators=[('grad_boost', grad_boost), ('lr', log_reg), ('ada_boost', ada_boost)]\n",
    "#create our voting classifier, inputting our models\n",
    "ensemble1 = VotingClassifier(estimators, voting='soft')\n",
    "ensemble1.fit(train_X, train_y)\n",
    "print('Training classification error: ' + str(1 - ensemble1.score(train_X, train_y)))\n",
    "print('Validation classification error: ' + str(1 - ensemble1.score(test_X, test_y)))\n",
    "\n",
    "# Predict probabilities for 1st voting classifier\n",
    "vot_pred1 = ensemble1.predict_proba(test.to_numpy())\n",
    "# Probabilities of being labeled 1\n",
    "vot_pred1 = pd.DataFrame(vot_pred1[:,1], columns=['Predicted'])\n",
    "vot_pred1.insert(0, 'id', test_ids)\n",
    "vot_pred1.to_csv(\"voting_probs_submission1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classification error: 0.36692405696323105\n",
      "Validation classification error: 0.3681772718613069\n"
     ]
    }
   ],
   "source": [
    "# Voting Classifier 2\n",
    "estimators=[('grad_boost', grad_boost), ('lr', log_reg), ('decision', tree)]\n",
    "#create our voting classifier, inputting our models\n",
    "ensemble2 = VotingClassifier(estimators, voting='soft')\n",
    "ensemble2.fit(train_X, train_y)\n",
    "print('Training classification error: ' + str(1 - ensemble2.score(train_X, train_y)))\n",
    "print('Validation classification error: ' + str(1 - ensemble2.score(test_X, test_y)))\n",
    "\n",
    "# Predict probabilities for 2nd voting classifier\n",
    "vot_pred2 = ensemble2.predict_proba(test.to_numpy())\n",
    "# Probabilities of being labeled 1\n",
    "vot_pred2 = pd.DataFrame(vot_pred2[:,1], columns=['Predicted'])\n",
    "vot_pred2.insert(0, 'id', test_ids)\n",
    "vot_pred2.to_csv(\"voting_probs_submission2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
